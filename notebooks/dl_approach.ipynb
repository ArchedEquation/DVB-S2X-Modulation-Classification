{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"symbol_features_noise.csv\")\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "data['modulation_label'] = label_enc.fit_transform(data['modulation_type'])\n",
    "features = data[['magnitude', 'phase', 'real', 'imag']].values\n",
    "labels = data['modulation_label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.15535884,  0.832327  , -0.31632448,  1.49304673],\n",
       "        [-1.85607457, -1.29231176, -0.32358172, -0.56616877],\n",
       "        [ 0.39753286, -0.1482755 ,  1.42358293,  0.02728151],\n",
       "        ...,\n",
       "        [ 0.15535884,  1.32262825, -1.23278156,  0.6796084 ],\n",
       "        [-0.83504684,  1.28176982, -0.87210457,  0.57757496],\n",
       "        [ 1.40011316,  0.28073809,  1.26111244,  1.44842205]]),\n",
       " array([[-0.1714682 , -0.31988094,  1.15535927, -0.39623083],\n",
       "        [-0.1714682 ,  0.36654081,  0.70803914,  1.13605121],\n",
       "        [-0.04701193,  1.56777888, -1.29259254,  0.02728151],\n",
       "        [-1.5264767 ,  1.28176982, -0.65325902,  0.43694644],\n",
       "        [-0.04701193,  1.56777888, -1.29259254,  0.02728151],\n",
       "        [-1.06992493, -1.34951357, -0.54651145, -0.78581627],\n",
       "        [ 0.39753286,  1.28176982, -1.26223032,  0.82826685],\n",
       "        [-0.83504684, -1.00630269, -0.01574005, -1.07330538],\n",
       "        [-0.27547906,  0.02332994,  1.1192063 ,  0.43771962],\n",
       "        [-0.83504684, -1.57832082, -0.87210457, -0.52301193],\n",
       "        [-0.04701193,  1.56777888, -1.29259254,  0.02728151],\n",
       "        [ 0.15535884, -0.63857675,  0.82647881, -1.14817093],\n",
       "        [-0.1714682 , -0.83469726,  0.36477319, -1.27615545],\n",
       "        [-0.04701193,  1.56777888, -1.29259254,  0.02728151],\n",
       "        [-2.02598333,  0.70975169, -0.01574005,  0.64342408],\n",
       "        [ 0.39753286,  0.13773356,  1.23075022,  0.82826685],\n",
       "        [ 0.15535884, -1.61917926, -1.23278156, -0.62504538],\n",
       "        [ 0.39753286, -1.57832082, -1.26223032, -0.77370382],\n",
       "        [ 0.72698853,  0.24773705,  1.15173548,  1.17845271],\n",
       "        [-1.5264767 , -0.72029363,  0.3523317 , -0.68227896],\n",
       "        [-1.85607457,  1.56777888, -0.6314234 ,  0.02728151],\n",
       "        [-1.5264767 , -1.57832082, -0.65325902, -0.38238342],\n",
       "        [ 0.72698853,  0.97376006, -0.74058326,  1.56442017],\n",
       "        [ 0.54082141, -1.70832494, -1.44700758, -0.44046694],\n",
       "        [-2.02598333,  1.56777888, -0.56932581,  0.02728151],\n",
       "        [-0.04701193,  1.56777888, -1.29259254,  0.02728151],\n",
       "        [ 0.15535884, -0.1482755 ,  1.33507412,  0.02728151],\n",
       "        [-0.1714682 , -0.40568366,  1.08141571, -0.59491915],\n",
       "        [-0.98974197,  1.32262825, -0.85571981,  0.47750558],\n",
       "        [-1.5264767 ,  1.28176982, -0.65325902,  0.43694644],\n",
       "        [ 0.15535884, -1.61917926, -1.23278156, -0.62504538],\n",
       "        [-0.04701193, -0.1482755 ,  1.26111244,  0.02728151],\n",
       "        [-0.51937457, -1.00630269, -0.01574005, -1.20171327],\n",
       "        [ 0.39753286,  1.28176982, -1.26223032,  0.82826685],\n",
       "        [-0.04701193, -0.1482755 ,  1.26111244,  0.02728151],\n",
       "        [-0.04701193, -0.1482755 ,  1.26111244,  0.02728151],\n",
       "        [-1.85607457,  0.70975169, -0.01574005,  0.71253887],\n",
       "        [ 0.39753286,  1.28176982, -1.26223032,  0.82826685],\n",
       "        [ 0.54082141, -1.31831258, -0.82220937, -1.36941556],\n",
       "        [ 0.54082141, -1.57832082, -1.3075828 , -0.80284699],\n",
       "        [ 1.40011316, -1.43531629, -1.29259254, -1.39385903],\n",
       "        [ 0.15535884, -0.1482755 ,  1.33507412,  0.02728151],\n",
       "        [ 1.40011316,  1.13876529, -1.29259254,  1.44842205],\n",
       "        [ 0.39753286,  0.42374263,  0.70392144,  1.41462881],\n",
       "        [-1.5264767 ,  0.42374263,  0.3523317 ,  0.73684198],\n",
       "        [ 0.86539085, -0.88372738,  0.3425885 , -1.72006624],\n",
       "        [ 0.77792734, -0.1482755 ,  1.56260802,  0.02728151],\n",
       "        [-1.5264767 ,  0.13773356,  0.62177892,  0.43694644],\n",
       "        [-1.06992493, -0.31988094,  0.84306612, -0.28329421],\n",
       "        [ 0.86539085, -0.1482755 ,  1.59457384,  0.02728151],\n",
       "        [ 0.15535884, -1.61917926, -1.23278156, -0.62504538],\n",
       "        [ 1.40011316, -0.5772891 ,  1.26111244, -1.39385903],\n",
       "        [-1.06992493,  0.36654081,  0.51503135,  0.84037929],\n",
       "        [ 0.15535884, -0.63857675,  0.82647881, -1.14817093],\n",
       "        [ 0.39753286, -0.72029363,  0.70392144, -1.36006579],\n",
       "        [ 0.39753286,  0.99576075, -0.73540154,  1.41462881],\n",
       "        [ 0.77792734, -1.64982309, -1.47394352, -0.64498077],\n",
       "        [-2.02598333,  0.70975169, -0.01574005,  0.64342408],\n",
       "        [ 1.40011316,  0.28073809,  1.26111244,  1.44842205],\n",
       "        [ 1.40011316,  1.13876529, -1.29259254,  1.44842205],\n",
       "        [-0.83504684,  1.28176982, -0.87210457,  0.57757496],\n",
       "        [ 0.54082141, -0.64229116,  0.90636247, -1.27776865],\n",
       "        [-1.06992493, -1.69272445, -0.87454622, -0.28329421],\n",
       "        [ 0.39753286, -0.72029363,  0.70392144, -1.36006579],\n",
       "        [ 0.15535884, -0.1482755 ,  1.33507412,  0.02728151],\n",
       "        [ 0.77792734, -1.64982309, -1.47394352, -0.64498077],\n",
       "        [-0.04701193, -0.1482755 ,  1.26111244,  0.02728151],\n",
       "        [ 0.54082141,  0.94375911, -0.6354111 ,  1.53750441],\n",
       "        [ 0.39753286,  1.56777888, -1.45506303,  0.02728151],\n",
       "        [-0.04701193,  1.56777888, -1.29259254,  0.02728151],\n",
       "        [ 0.86539085, -1.37402863, -1.01975434, -1.37398259],\n",
       "        [ 1.40011316, -0.5772891 ,  1.26111244, -1.39385903],\n",
       "        [-0.27547906, -0.89189907,  0.23237204, -1.27189962],\n",
       "        [-0.04701193, -0.1482755 ,  1.26111244,  0.02728151],\n",
       "        [-0.04701193,  1.56777888, -1.29259254,  0.02728151],\n",
       "        [ 1.40011316,  0.28073809,  1.26111244,  1.44842205],\n",
       "        [-2.02598333,  1.56777888, -0.56932581,  0.02728151],\n",
       "        [ 0.77792734, -0.1482755 ,  1.56260802,  0.02728151],\n",
       "        [ 0.86539085, -0.88372738,  0.3425885 , -1.72006624],\n",
       "        [-1.5264767 , -0.1482755 ,  0.72040344,  0.02728151],\n",
       "        [ 0.77792734,  0.28073809,  1.10032057,  1.26946023],\n",
       "        [ 1.40011316,  1.13876529, -1.29259254,  1.44842205],\n",
       "        [-0.04701193, -0.1482755 ,  1.26111244,  0.02728151],\n",
       "        [-0.04701193,  1.56777888, -1.29259254,  0.02728151],\n",
       "        [-0.51937457,  0.02332994,  1.03443105,  0.40706178],\n",
       "        [-0.98974197, -0.1482755 ,  0.91656715,  0.02728151],\n",
       "        [-0.27547906,  0.65254988,  0.10899933,  1.34821107],\n",
       "        [-2.11912719, -0.1482755 ,  0.50380386,  0.02728151],\n",
       "        [ 0.39753286,  0.70975169, -0.01574005,  1.62925218],\n",
       "        [-0.04701193,  1.56777888, -1.29259254,  0.02728151],\n",
       "        [-0.1714682 ,  0.45234353,  0.54328873,  1.24841907],\n",
       "        [-0.98974197,  0.832327  , -0.22319792,  1.03892582],\n",
       "        [ 0.15535884,  1.32262825, -1.23278156,  0.6796084 ],\n",
       "        [ 0.39753286, -1.00630269, -0.01574005, -1.57468916],\n",
       "        [ 0.72698853, -0.54428805,  1.15173548, -1.12388969],\n",
       "        [-0.1714682 ,  0.79555441, -0.20836824,  1.38092292],\n",
       "        [ 0.54082141,  0.65775004,  0.12605424,  1.68002075],\n",
       "        [ 0.54082141, -1.42231588, -1.04512506, -1.174303  ],\n",
       "        [-0.04701193, -0.1482755 ,  1.26111244,  0.02728151],\n",
       "        [-0.27547906,  0.82415531, -0.26385213,  1.32646264],\n",
       "        [ 1.40011316,  0.28073809,  1.26111244,  1.44842205],\n",
       "        [-0.83504684, -0.43428457,  0.84062447, -0.52301193],\n",
       "        [-0.04701193, -0.1482755 ,  1.26111244,  0.02728151],\n",
       "        [ 1.40011316,  0.28073809,  1.26111244,  1.44842205],\n",
       "        [-0.04701193,  1.56777888, -1.29259254,  0.02728151],\n",
       "        [ 0.15535884,  0.34202575,  0.82647881,  1.20273395],\n",
       "        [ 0.39753286, -0.1482755 ,  1.42358293,  0.02728151],\n",
       "        [ 0.54082141, -0.66829198,  0.84952592, -1.32512392],\n",
       "        [ 0.15535884,  0.832327  , -0.31632448,  1.49304673],\n",
       "        [ 0.39753286,  0.99576075, -0.73540154,  1.41462881],\n",
       "        [ 0.77792734, -1.64982309, -1.47394352, -0.64498077],\n",
       "        [-1.5264767 ,  0.99576075, -0.3838118 ,  0.73684198],\n",
       "        [-0.04701193, -0.1482755 ,  1.26111244,  0.02728151],\n",
       "        [-0.04701193,  1.56777888, -1.29259254,  0.02728151],\n",
       "        [-2.11215512, -1.00630269, -0.01574005, -0.55380844],\n",
       "        [ 1.40011316, -0.5772891 ,  1.26111244, -1.39385903],\n",
       "        [ 0.86539085, -1.61917926, -1.46658273, -0.7503614 ],\n",
       "        [ 0.54082141,  1.33377146, -1.37263038,  0.7169772 ],\n",
       "        [ 0.15535884, -0.63857675,  0.82647881, -1.14817093],\n",
       "        [ 0.15535884,  0.34202575,  0.82647881,  1.20273395],\n",
       "        [ 0.39753286,  1.56777888, -1.45506303,  0.02728151],\n",
       "        [ 0.39753286,  1.28176982, -1.26223032,  0.82826685],\n",
       "        [ 1.40011316, -0.5772891 ,  1.26111244, -1.39385903],\n",
       "        [ 0.54082141,  1.1517657 , -1.09532798,  1.17299003],\n",
       "        [ 0.15535884, -1.61917926, -1.23278156, -0.62504538],\n",
       "        [ 0.15535884, -0.1482755 ,  1.33507412,  0.02728151],\n",
       "        [-0.51937457, -1.17790813, -0.35696132, -1.14156198],\n",
       "        [-0.04701193, -0.1482755 ,  1.26111244,  0.02728151],\n",
       "        [ 0.15535884,  0.34202575,  0.82647881,  1.20273395],\n",
       "        [-0.1714682 ,  1.31037072, -1.11289581,  0.64948217],\n",
       "        [-0.1714682 , -1.17790813, -0.39625329, -1.27615545],\n",
       "        [ 0.15535884, -0.1482755 ,  1.33507412,  0.02728151],\n",
       "        [-0.04701193,  1.56777888, -1.29259254,  0.02728151],\n",
       "        [-0.1714682 , -0.23407822,  1.20046648, -0.18711423],\n",
       "        [-2.02598333,  0.70975169, -0.01574005,  0.64342408],\n",
       "        [ 0.86539085,  1.32262825, -1.46658273,  0.80492442],\n",
       "        [-2.11215512, -1.57832082, -0.46788501, -0.26326347],\n",
       "        [-2.02598333, -0.1482755 ,  0.53784571,  0.02728151],\n",
       "        [-0.1714682 ,  0.79555441, -0.20836824,  1.38092292],\n",
       "        [-0.83504684, -0.72029363,  0.47868224, -0.9258547 ],\n",
       "        [ 0.15535884,  1.32262825, -1.23278156,  0.6796084 ],\n",
       "        [ 0.86539085,  1.32262825, -1.46658273,  0.80492442],\n",
       "        [ 0.77792734, -1.22080949, -0.61974771, -1.59570321],\n",
       "        [ 0.15535884, -1.12887801, -0.31632448, -1.43848371],\n",
       "        [-0.04701193, -0.1482755 ,  1.26111244,  0.02728151],\n",
       "        [ 0.77792734,  1.35327208, -1.47394352,  0.69954379],\n",
       "        [ 1.40011316, -0.5772891 ,  1.26111244, -1.39385903],\n",
       "        [ 0.39753286, -1.29231176, -0.73540154, -1.36006579],\n",
       "        [-1.06992493,  1.56777888, -0.9187423 ,  0.02728151],\n",
       "        [ 0.86539085,  0.46460106,  0.68294896,  1.64207364],\n",
       "        [ 0.72698853, -1.79832779, -1.56409901, -0.1819684 ],\n",
       "        [-0.04701193, -0.1482755 ,  1.26111244,  0.02728151],\n",
       "        [ 0.54082141,  1.07376323, -0.93784257,  1.33233167],\n",
       "        [-2.11215512, -0.72029363,  0.24530597, -0.47595715],\n",
       "        [-0.51937457, -0.1482755 ,  1.08847519,  0.02728151],\n",
       "        [ 0.86539085, -0.88372738,  0.3425885 , -1.72006624],\n",
       "        [ 0.54082141, -0.56428869,  1.06384788, -1.118427  ],\n",
       "        [ 0.54082141,  1.43777476, -1.46538313,  0.41870194],\n",
       "        [-0.51937457,  0.02332994,  1.03443105,  0.40706178],\n",
       "        [-1.85607457,  0.42374263,  0.29210162,  0.62073179]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "Xts_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "ytr_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "yts_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(Xtr_tensor, ytr_tensor)\n",
    "test_dataset = TensorDataset(Xts_tensor, yts_tensor)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "\n",
    "class ModulationClassifier(nn.Module): \n",
    "    def __init__(self, input_size, num_classes): \n",
    "        super(ModulationClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "    \n",
    "    def forward(self, x): \n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.drop(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "input_size: int = 4\n",
    "num_classes = len(label_enc.classes_)\n",
    "model = ModulationClassifier(input_size, num_classes).to(device)\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 2.0531\n",
      "Epoch [2/100], Loss: 1.9724\n",
      "Epoch [3/100], Loss: 1.8824\n",
      "Epoch [4/100], Loss: 1.7899\n",
      "Epoch [5/100], Loss: 1.7207\n",
      "Epoch [6/100], Loss: 1.6542\n",
      "Epoch [7/100], Loss: 1.5828\n",
      "Epoch [8/100], Loss: 1.5440\n",
      "Epoch [9/100], Loss: 1.4913\n",
      "Epoch [10/100], Loss: 1.4534\n",
      "Epoch [11/100], Loss: 1.4179\n",
      "Epoch [12/100], Loss: 1.3884\n",
      "Epoch [13/100], Loss: 1.3649\n",
      "Epoch [14/100], Loss: 1.3267\n",
      "Epoch [15/100], Loss: 1.3069\n",
      "Epoch [16/100], Loss: 1.2871\n",
      "Epoch [17/100], Loss: 1.2482\n",
      "Epoch [18/100], Loss: 1.2214\n",
      "Epoch [19/100], Loss: 1.2084\n",
      "Epoch [20/100], Loss: 1.1898\n",
      "Epoch [21/100], Loss: 1.1693\n",
      "Epoch [22/100], Loss: 1.1507\n",
      "Epoch [23/100], Loss: 1.1188\n",
      "Epoch [24/100], Loss: 1.1053\n",
      "Epoch [25/100], Loss: 1.0859\n",
      "Epoch [26/100], Loss: 1.0698\n",
      "Epoch [27/100], Loss: 1.0500\n",
      "Epoch [28/100], Loss: 1.0333\n",
      "Epoch [29/100], Loss: 1.0184\n",
      "Epoch [30/100], Loss: 0.9949\n",
      "Epoch [31/100], Loss: 0.9872\n",
      "Epoch [32/100], Loss: 0.9639\n",
      "Epoch [33/100], Loss: 0.9657\n",
      "Epoch [34/100], Loss: 0.9546\n",
      "Epoch [35/100], Loss: 0.9308\n",
      "Epoch [36/100], Loss: 0.9155\n",
      "Epoch [37/100], Loss: 0.9141\n",
      "Epoch [38/100], Loss: 0.9064\n",
      "Epoch [39/100], Loss: 0.8874\n",
      "Epoch [40/100], Loss: 0.8677\n",
      "Epoch [41/100], Loss: 0.8513\n",
      "Epoch [42/100], Loss: 0.8681\n",
      "Epoch [43/100], Loss: 0.8579\n",
      "Epoch [44/100], Loss: 0.8380\n",
      "Epoch [45/100], Loss: 0.8118\n",
      "Epoch [46/100], Loss: 0.8265\n",
      "Epoch [47/100], Loss: 0.8172\n",
      "Epoch [48/100], Loss: 0.8048\n",
      "Epoch [49/100], Loss: 0.7811\n",
      "Epoch [50/100], Loss: 0.7992\n",
      "Epoch [51/100], Loss: 0.7877\n",
      "Epoch [52/100], Loss: 0.7668\n",
      "Epoch [53/100], Loss: 0.7761\n",
      "Epoch [54/100], Loss: 0.7607\n",
      "Epoch [55/100], Loss: 0.7522\n",
      "Epoch [56/100], Loss: 0.7543\n",
      "Epoch [57/100], Loss: 0.7447\n",
      "Epoch [58/100], Loss: 0.7542\n",
      "Epoch [59/100], Loss: 0.7474\n",
      "Epoch [60/100], Loss: 0.7543\n",
      "Epoch [61/100], Loss: 0.7436\n",
      "Epoch [62/100], Loss: 0.7317\n",
      "Epoch [63/100], Loss: 0.7186\n",
      "Epoch [64/100], Loss: 0.7171\n",
      "Epoch [65/100], Loss: 0.7260\n",
      "Epoch [66/100], Loss: 0.7122\n",
      "Epoch [67/100], Loss: 0.6992\n",
      "Epoch [68/100], Loss: 0.6878\n",
      "Epoch [69/100], Loss: 0.6991\n",
      "Epoch [70/100], Loss: 0.6901\n",
      "Epoch [71/100], Loss: 0.7102\n",
      "Epoch [72/100], Loss: 0.6910\n",
      "Epoch [73/100], Loss: 0.7110\n",
      "Epoch [74/100], Loss: 0.6878\n",
      "Epoch [75/100], Loss: 0.6685\n",
      "Epoch [76/100], Loss: 0.6836\n",
      "Epoch [77/100], Loss: 0.6647\n",
      "Epoch [78/100], Loss: 0.6711\n",
      "Epoch [79/100], Loss: 0.6601\n",
      "Epoch [80/100], Loss: 0.6633\n",
      "Epoch [81/100], Loss: 0.6632\n",
      "Epoch [82/100], Loss: 0.6694\n",
      "Epoch [83/100], Loss: 0.6655\n",
      "Epoch [84/100], Loss: 0.6699\n",
      "Epoch [85/100], Loss: 0.6299\n",
      "Epoch [86/100], Loss: 0.6355\n",
      "Epoch [87/100], Loss: 0.6508\n",
      "Epoch [88/100], Loss: 0.6536\n",
      "Epoch [89/100], Loss: 0.6412\n",
      "Epoch [90/100], Loss: 0.6303\n",
      "Epoch [91/100], Loss: 0.6397\n",
      "Epoch [92/100], Loss: 0.6279\n",
      "Epoch [93/100], Loss: 0.6544\n",
      "Epoch [94/100], Loss: 0.6449\n",
      "Epoch [95/100], Loss: 0.6293\n",
      "Epoch [96/100], Loss: 0.6386\n",
      "Epoch [97/100], Loss: 0.6591\n",
      "Epoch [98/100], Loss: 0.6272\n",
      "Epoch [99/100], Loss: 0.6199\n",
      "Epoch [100/100], Loss: 0.6163\n",
      "Test Accuracy: 76.25%\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=20):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Ensure labels are of type Long\n",
    "            labels = labels.long()\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# Train and evaluate the model\n",
    "train_model(model, train_dataloader, criterion, optimizer, num_epochs=100)\n",
    "evaluate_model(model, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sih24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
